## Deep learning
- [http://laid.delanover.com/](http://laid.delanover.com/)
- [What should I do when my neural network doesn't learn?](https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn)
- [Understanding Learning Rates and How It Improves Performance in Deep Learning](https://www.kdnuggets.com/2018/02/understanding-learning-rates-improves-performance-deep-learning.html)
- [Tradeoff batch size vs. number of iterations to train a neural network](https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network)
- [Don't Decay the Learning Rate, Increase the Batch Size](https://openreview.net/forum?id=B1Yy1BxCZ)
- [A listing of my articles in deep learning & reinforcement learning (Jonathan Hui)](https://medium.com/@jonathan_hui/index-page-for-my-articles-in-deep-learning-19821810a14)
- [Convolution arithmetic tutorial](http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html)
- [Convolution arithmetic](https://github.com/vdumoulin/conv_arithmetic)
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
- [Conv Nets: A Modular Perspective](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)
- [Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)
- [Intro to optimization in deep learning: Gradient Descent](https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/)
- [Intro to optimization in deep learning: Vanishing gradients and choosing the right activation function](https://blog.paperspace.com/vanishing-gradients-activation-function/)
- [Intro to optimization in deep learning: Busting the myth about batch normalization](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)
- [Intro to optimization in deep learning: Momentum, RMSProp and Adam](https://medium.com/paperspace/intro-to-optimization-in-deep-learning-momentum-rmsprop-and-adam-8335f15fdee2)
- [Understanding Learning Rates and How It Improves Performance in Deep Learning](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)
- [Realtime Interactive Visualization of Convolutional Neural Networks in Unity](https://vimeo.com/274236414)

## Courses
- [Deep Natural Language Processing, University of Oxford, 2017](https://github.com/oxford-cs-deepnlp-2017/lectures)
- [Reconnaissance des formes et méthodes neuronales (US330X) - Master TRIED - Neural Networks and Deep Learning](http://cedric.cnam.fr/~thomen/cours/US330X.html)
  - [http://cedric.cnam.fr/~thomen/cours/US330X/cours1.pdf](http://cedric.cnam.fr/~thomen/cours/US330X/cours1.pdf)
  - [http://cedric.cnam.fr/~thomen/cours/US330X/cours2.pdf](http://cedric.cnam.fr/~thomen/cours/US330X/cours2.pdf)
  - [TP Réseaux de neurones et Apprentissage profond (US330X)](http://cedric.cnam.fr/~thomen/cours/US330X/)
- [Artificial intelligence and machine learning](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/)
- [Deconvolutional Networks](https://cs.nyu.edu/~fergus/drafts/utexas2.pdf)
- [Fully Convolutional Networks](http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf)
- [A Fuller Understanding of Fully Convolutional Networks](http://www.micc.unifi.it/bagdanov/pdfs/FCN-presentation.pdf)
- [Image Segmentation using deconvolution layer in Tensorflow](https://cv-tricks.com/image-segmentation/transpose-convolution-in-tensorflow/)
- [Deep Learning Tutorials](http://deeplearning.net/tutorial/contents.html)
- [fast.ai](https://www.fast.ai/) ([wiki](http://wiki.fast.ai/index.php/Main_Page))
- [Computational Linear Algebra for Coders](https://github.com/fastai/numerical-linear-algebra)

## Object Detection
- [Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning](https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab)
- [Understand Single Shot MultiBox Detector (SSD) and Implement It in Pytorch](https://medium.com/@smallfishbigsea/understand-ssd-and-implement-your-own-caa3232cd6ad)
- [[SSD] Small object detection #3196](https://github.com/tensorflow/models/issues/3196)
- [MobileNet version 2](http://machinethink.net/blog/mobilenet-v2/)
- [TensorFlow Object Detection API: basics of detection (1/2)](https://becominghuman.ai/tensorflow-object-detection-api-basics-of-detection-7b134d689c75)
- [TensorFlow Object Detection API: basics of detection (2/2)](https://becominghuman.ai/tensorflow-object-detection-api-basics-of-detection-2-2-28b348495eec)
- [Faster R-CNN: Down the rabbit hole of modern object detection](https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/)
- [Deep Learning for Object Detection: A Comprehensive Review](https://www.kdnuggets.com/2017/10/deep-learning-object-detection-comprehensive-review.html)
- [A Comprehensive guide to Fine-tuning Deep Learning Models in Keras (Part I)](https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html)
- [A Comprehensive guide to Fine-tuning Deep Learning Models in Keras (Part II)](https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html)
- [Understanding Feature Pyramid Networks for object detection (FPN)](https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c)
- [Object detection: speed and accuracy comparison (Faster R-CNN, R-FCN, SSD, FPN, RetinaNet and YOLOv3)](https://medium.com/@jonathan_hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359)
- [What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)?](https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9)
- [What do we learn from single shot object detectors (SSD, YOLOv3), FPN & Focal loss (RetinaNet)?](https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d)
- [Design choices, lessons learned and trends for object detections?](https://medium.com/@jonathan_hui/design-choices-lessons-learned-and-trends-for-object-detections-4f48b59ec5ff)
- [The intuition behind RetinaNet](https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d)
- [Object Detection (Part 1)](https://www.saagie.com/fr/blog/object-detection-part1)
- [Object Detection (Part 2)](https://www.saagie.com/fr/blog/object-detection-part2)
- [Focus : MobileNet-SSD, pour identifier les objets avec une caméra de smartphone !](http://penseeartificielle.fr/mobilenet-ssd-identifier-objets-camera-smartphone/)
- [Review of Deep Learning Algorithms for Object Detection](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
- [Faster R-CNN Explained](https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8)
- [Evolution of Object Detection and Localization Algorithms](https://towardsdatascience.com/evolution-of-object-detection-and-localization-algorithms-e241021d8bad)
- [Why GEMM is at the heart of deep learning](https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/)
- [Optimizing Mobile Deep Learning on ARM GPU with TVM ](https://tvm.ai/2018/01/16/opt-mali-gpu.html)
- [Optimize Deep Learning GPU Operators with TVM: A Depthwise Convolution Example](https://tvm.ai/2017/08/22/Optimize-Deep-Learning-GPU-Operators-with-TVM-A-Depthwise-Convolution-Example.html)
- [Google’s MobileNets on the iPhone](http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/)
- [How fast is my model?](http://machinethink.net/blog/how-fast-is-my-model/)
- [One-shot object detection](http://machinethink.net/blog/object-detection/)
- [How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 1](https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/)
- [How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 2](https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-2/)
- [How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 3](https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-3/)
- [How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 4](https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-4/)
- [How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 5](https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-5/)

## Object Tracking
- [ATOM: Accurate Tracking by Overlap Maximization, Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg, Published in CVPR 2018](https://www.semanticscholar.org/paper/ATOM%3A-Accurate-Tracking-by-Overlap-Maximization-Danelljan-Bhat/d74169a8fd2f90a06480d1d583d0ae5e980ea951)
- [PyTracking](https://github.com/visionml/pytracking)

## Deep learning hardware accelerators
- [A List of Chip/IP for Deep Learning](https://medium.com/@shan.tang.g/a-list-of-chip-ip-for-deep-learning-48d05f1759ae)
- [FPGAs and AI processors: DNN and CNN for all](https://meanderful.blogspot.com/2017/06/fpgas-and-ai-processors-dnn-and-cnn-for.html)
- [AI/ML/DL ICs and IPs](https://github.com/basicmi/Deep-Learning-Processor-List)
- [Neural Network Accelerator Inference](https://nicsefc.ee.tsinghua.edu.cn/projects/neural-network-accelerator/)
- [The AI revolution has spawned a new chips arms race](https://arstechnica.com/gadgets/2018/07/the-ai-revolution-has-spawned-a-new-chips-arms-race)
- [Hands-on with the Google TPUv2](https://medium.com/paperspace/hands-on-with-the-google-tpuv2-9feb0c5ea952)
- [How AI is decommoditizing the chip industry](https://venturebeat.com/2018/08/16/how-ai-is-decommoditizing-the-chip-industry/)
- [AI performance, not stories - 15,000 images/sec on ResNet-50. Production-ready.](https://habana.ai/)
- ["Mythic's Analog Deep Learning Accelerator Chip: High Performance Inference," a Presentation from Mythic](https://www.embedded-vision.com/platinum-members/mythic/embedded-vision-training/videos/pages/may-2018-embedded-vision-summit)
- [Mythic](https://www.mythic-ai.com/)
- [Mythic Multiplies in a Flash - Analog In-Memory Computing Eliminates DRAM Read/Write Cycles](https://www.mythic-ai.com/wp-content/uploads/2018/08/Mythic-Multiplies-In-A-Flash.pdf)
- [Syntiant](https://www.syntiant.com/)
- [Xnor.ai](https://www.xnor.ai/)
- [NovuMind](https://www.novumind.com/)

## Deep learning optimization
- [Optimizing CNN Model Inference on CPUs, Yizhi Liu, Yao Wang, Ruofei Yu, Mu Li, Vin Sharma, Yida Wang, Published in USENIX Annual Technical Conference 2018](https://www.semanticscholar.org/paper/Optimizing-CNN-Model-Inference-on-CPUs-Liu-Wang/9d60ea2461172d30487743fa6ef8788db4b53759) ([pdf](https://www.usenix.org/system/files/atc19-liu-yizhi.pdf), [presentation](https://www.usenix.org/conference/atc19/presentation/liu-yizhi))
- [TVM and Deep Learning Compiler Conference](https://sampl.cs.washington.edu/tvmconf/)
- [Deep Learning Compiler](https://sampl.cs.washington.edu/tvmconf/slides/Yida-Wang-TVM-AWS.pdf)
- [TVM Stack Overview](https://sampl.cs.washington.edu/tvmconf/slides/Tianqi-Chen-TVM-Stack-Overview.pdf)
- [Supporting TVM on RISC-V Architectures](https://sampl.cs.washington.edu/tvmconf/slides/07-Jenq-Kuen-Lee.pdf)
- [Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications, Published in ArXiv 2018](https://www.semanticscholar.org/paper/Deep-Learning-Inference-in-Facebook-Data-Centers%3A-Park-Naumov/611e0bd5d466668989df04d642104428d03eaeb6)

## Transfer learning
- [Transfer Learning (CS231n)](https://cs231n.github.io/transfer-learning/)
- [Transfer Learning and Fine Tuning: Let's discuss.](https://www.linkedin.com/pulse/transfer-learning-fine-tuning-lets-discuss-arun-das)
- [Deep Learning Part 2: Transfer Learning and Fine-tuning Deep Convolutional Neural Networks](https://blog.revolutionanalytics.com/2016/08/deep-learning-part-2.html)
- [How to Retrain an Image Classifier for New Categories](https://www.tensorflow.org/hub/tutorials/image_retraining)
- [How transfer learning happening in tensorfow object detection API ? Can we keep feature extractors weight unchanged while only changing the predictor weights . #2203](https://github.com/tensorflow/models/issues/2203)
- [from_detection_checkpoint missed in faster_rcnn_inception_resnet_v2_atrous_oid.config #3562](https://github.com/tensorflow/models/issues/3562)
- [Configuring the Object Detection Training Pipeline](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md#model-parameter-initialization)
- [A Comprehensive guide to Fine-tuning Deep Learning Models in Keras (Part I)](https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html)
- [A Comprehensive guide to Fine-tuning Deep Learning Models in Keras (Part II)](https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html)
- [Mask R-CNN - Train on Shapes Dataset](https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb)
- [5th place solution (based only on Mask-RCNN)](https://www.kaggle.com/c/data-science-bowl-2018/discussion/56326)
- [Train & Test Image Mosaic](https://www.kaggle.com/bonlime/train-test-image-mosaic)
- [Must Know Tips/Tricks in Deep Neural Networks (by Xiu-Shen Wei)](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)

## Hardware
- [Hardware for Deep Learning. Part 1: Introduction](https://blog.inten.to/hardware-for-deep-learning-current-state-and-trends-51c01ebbb6dc)
- [Hardware for Deep Learning. Part 2: CPU](https://blog.inten.to/cpu-hardware-for-deep-learning-b91f53cb18af)
- [Hardware for Deep Learning. Part 3: GPU](https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664)

## Benchmark
- [MLPerf](https://mlperf.org/)
- [sotabench](https://sotabench.com/)

## Books
- [Deep Learning book](http://www.deeplearningbook.org/)
- [Reinforcement Learning: An Introduction, Richard S. Sutton and Andrew G. Barto, Second Edition, MIT Press, Cambridge, MA, 2018](http://incompleteideas.net/book/the-book-2nd.html) ([pdf](http://incompleteideas.net/book/RLbook2018.pdf), [Google Drive](https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view))
- [Dive into Deep Learning, Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola](https://d2l.ai/) ([pdf](https://en.d2l.ai/d2l-en.pdf))

## Articles
- [Benchmarking Machine Learning on the New Raspberry Pi 4, Model B](https://blog.hackster.io/benchmarking-machine-learning-on-the-new-raspberry-pi-4-model-b-88db9304ce4)
- [Benchmarking Edge Computing](https://medium.com/@aallan/benchmarking-edge-computing-ce3f13942245)
- [Benchmarking the Intel Neural Compute Stick on the New Raspberry Pi 4, Model B](https://blog.hackster.io/benchmarking-the-intel-neural-compute-stick-on-the-new-raspberry-pi-4-model-b-e419393f2f97)
- [A 2017 Guide to Semantic Segmentation with Deep Learning, Sasank Chilamkurthy, July 5, 2017](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review)
- [Interviews with Machine Learning Heroes](https://hackernoon.com/interviews-with-machine-learning-heroes-504762ba5dd6)
- [Anatomy of a High-Speed Convolution](https://sahnimanas.github.io/post/anatomy-of-a-high-performance-convolution/)
- [Benchmarking Transformers: PyTorch and TensorFlow](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2)

## Papers
- [Deep Learning Resources (DL4J)](https://deeplearning4j.org/cn/deeplearningpapers)
- [Deep Multi-modal Object Detection and Semantic Segmentation for Autonomous Driving: Datasets, Methods, and Challenges, Di Feng, Christian Haase-Schuetz, Lars Rosenbaum, Heinz Hertlein, Fabian Duffhauss, Claudius Gläser, Werner Wiesbeck, Klaus C. J. Dietmayer, Published in ArXiv 2019](https://www.semanticscholar.org/paper/Deep-Multi-modal-Object-Detection-and-Semantic-for-Feng-Haase-Schuetz/641e8208f7a1a5510ab167b18daeb7e81efdd83b) ([arXiv](https://arxiv.org/abs/1902.07830))
- [Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving, Yan Wang, Wei-Lun Chao, Divyansh Garg, Bharath Hariharan, Mark Campbell, Kilian Q. Weinberger, Published in ArXiv 2018](https://www.semanticscholar.org/paper/Pseudo-LiDAR-from-Visual-Depth-Estimation%3A-Bridging-Wang-Chao/1c880573742d2cde2e7554162ab13a0632534ea9) ([arXiv](https://arxiv.org/abs/1812.07179))
- [Multi-view 3D Object Detection Network for Autonomous Driving, Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, Tian Xia, DOI:10.1109/CVPR.2017.691, IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017](https://www.semanticscholar.org/paper/Multi-view-3D-Object-Detection-Network-for-Driving-Chen-Ma/2e016c61724304980dc2c82b7d60896fd921c176) ([arXiv](https://arxiv.org/abs/1611.07759))
- [NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection, Golnaz Ghiasi, Tsung-Yi Lin, Ruoming Pang, Quoc V. Le, Published in ArXiv 2019](https://www.semanticscholar.org/paper/NAS-FPN%3A-Learning-Scalable-Feature-Pyramid-for-Ghiasi-Lin/7b89427b330960fd82876b607e1671d29f9f2497) ([arXiv](https://arxiv.org/abs/1904.07392))
- [Understanding the Limitations of CNN-based Absolute Camera Pose Regression, Torsten Sattler, Qunjie Zhou, Marc Pollefeys, Laura Leal-Taixé, Published in ArXiv 2019](https://www.semanticscholar.org/paper/Understanding-the-Limitations-of-CNN-based-Absolute-Sattler-Zhou/a550802ba94933dee3d10f7d24091ee621e57b0b) ([arXiv](https://arxiv.org/abs/1903.07504))
- [Zero-Shot Semantic Segmentation, Maxime Bucher, Tuan-Hung Vu, Matthieu Cord, Patrick Pérez, Published in ArXiv 2019](https://www.semanticscholar.org/paper/Zero-Shot-Semantic-Segmentation-Bucher-Vu/ff24ced52576b5da970c1397227e2c14933e7891) ([arXiv](https://arxiv.org/abs/1906.00817))
- [Zero-Shot Semantic Segmentation](https://github.com/RohanDoshi2018/ZeroshotSemanticSegmentation)
- [Learning SO(3) Equivariant Representations with Spherical CNNs, Carlos Esteves, Christine Allen-Blanchette, Ameesh Makadia, Kostas Daniilidis, Published in ECCV 2018, https://doi.org/10.1007/978-3-030-01261-8_4](https://www.semanticscholar.org/paper/Learning-SO(3)-Equivariant-Representations-with-Esteves-Allen-Blanchette/1ec575e06a69e0c04961c2caab9d90c26c931703) ([code](https://github.com/daniilidis-group/spherical-cnn))
- [SuperPoint: Self-Supervised Interest Point Detection and Description, Daniel DeTone, Tomasz Malisiewicz, Andrew Rabinovich, IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) (2018), https://doi.org/10.1109/CVPRW.2018.00060](https://www.semanticscholar.org/paper/SuperPoint%3A-Self-Supervised-Interest-Point-and-DeTone-Malisiewicz/a62bdda9ae6f86fc06d7edf5d3b429eda3a6640e) ([SuperPointPretrainedNetwork](https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork), [SuperPoint](https://github.com/rpautrat/SuperPoint))
- [Catastrophic interference in connectionist networks: The sequential learning problem" The Psychology, M. Mccloskey, Published 1989, https://doi.org/10.1016/s0079-7421%2808%2960536-8](https://www.semanticscholar.org/paper/Catastrophic-interference-in-connectionist-The-The-Mccloskey/c213af6582c0d518a6e8e14217611c733eeb1ef1)
- [Continual lifelong learning with neural networks: A review, German Ignacio Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, Stefan Wermter, Published in Neural Networks 2019, https://doi.org/10.1016/j.neunet.2019.01.012](https://www.semanticscholar.org/paper/Continual-lifelong-learning-with-neural-networks%3A-A-Parisi-Kemker/867f85cbae54a1d17a39182063aebf8319fc2597) ([full access](https://www.sciencedirect.com/science/article/pii/S0893608019300231))
- [Incremental learning algorithms and applications, Alexander Gepperth, Barbara Hammer, Published in ESANN 2016](https://www.semanticscholar.org/paper/Incremental-learning-algorithms-and-applications-Gepperth-Hammer/5a34bd8a6a992f3e5d60256ed055d9da80a0239f) ([HAL](https://hal.inria.fr/hal-01418129))
- [Deep learning in neural networks: An overview, Jürgen Schmidhuber, Published in Neural Networks 2015, https://doi.org/10.1016/j.neunet.2014.09.003](https://www.semanticscholar.org/paper/Deep-learning-in-neural-networks%3A-An-overview-Schmidhuber/126df9f24e29feee6e49e135da102fbbd9154a48)
- [Automatic Full Compilation of Julia Programs and ML Models to Cloud TPUs, Keno Fischer, Elliot Saba, Published in ArXiv 2018](https://www.semanticscholar.org/paper/Automatic-Full-Compilation-of-Julia-Programs-and-ML-Fischer-Saba/3c07aa4b70ee763b1c2f4b1e745deb5444dc6de5)
- [Benchmarking of CNNs for Low-Cost, Low-Power Robotics Applications, Dexmont Peña, Andrew Forembski, Xiaofan Xu, David Moloney, Published 2017](https://www.semanticscholar.org/paper/Benchmarking-of-CNNs-for-Low-Cost-%2C-Low-Power-Pe%C3%B1a-Forembski/340632b4085655046ee5c4d93de6c4aea6996d66) ([pdf](http://juxi.net/workshop/deep-learning-rss-2017/papers/Pena.pdf))
- [Evaluating the Search Phase of Neural Architecture Search, Christian Sciuto, Kaicheng Yu, Martin Jaggi, Claudiu Cristian Musat, Mathieu Salzmann, Published in ArXiv 2019](https://www.semanticscholar.org/paper/Evaluating-the-Search-Phase-of-Neural-Architecture-Sciuto-Yu/6eb3a62cd365e4f9792eedca43c90595e1a862ba)
- [AutoAugment: Learning Augmentation Policies from Data, Ekin Dogus Cubuk, Barret Zoph, Dandelion Mané, Vijay Vasudevan, Quoc V. Le, Published in ArXiv 2018](https://www.semanticscholar.org/paper/AutoAugment%3A-Learning-Augmentation-Policies-from-Cubuk-Zoph/f723eb3e7159f07b97464c8d947d15e78612abe4)
- [Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras, Andrew Gordon, Hanhan Li, Rico Jonschkowski, Anelia Angelova, Published in ArXiv 2019](https://www.semanticscholar.org/paper/Depth-from-Videos-in-the-Wild%3A-Unsupervised-Depth-Gordon-Li/b51d23b2cd972a75c854ca7fe863122eeac895f6)
- [Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis, Wen Liu, Zhixin Piao, Jie Min, Wenhan Luo, Lin Ma, Shenghua Gao, Published in ArXiv 2019](https://www.semanticscholar.org/paper/Liquid-Warping-GAN%3A-A-Unified-Framework-for-Human-Liu-Piao/f672ec28c095f3d3f44a71e55e951cd888bbbc2b) ([project page](https://svip-lab.github.io/project/impersonator), [Impersonator](https://github.com/svip-lab/impersonator))
- [MixConv: Mixed Depthwise Convolutional Kernels, Mingxing Tan, Quoc V. Le](https://www.semanticscholar.org/paper/MixConv%3A-Mixed-Depthwise-Convolutional-Kernels-Tan-Le/fb564bacfa790d44ab02a72256d55aa8b2209914) ([BMVC 2019](https://bmvc2019.org/wp-content/uploads/papers/0583-paper.pdf), [TF TPU](https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mixnet/README.md))
- [Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving, Jiwoong Choi, Dayoung Chun, Hyun Kim, Hyuk-Jae Lee](https://www.semanticscholar.org/paper/Gaussian-YOLOv3%3A-An-Accurate-and-Fast-Object-Using-Choi-Chun/e263db19d0714803879727801f1a700d928f9233) ([ICCV 2019 code](https://github.com/jwchoi384/Gaussian_YOLOv3))
- [Language Models are Unsupervised Multitask Learners, Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever](https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe) ([paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), [code](https://github.com/openai/gpt-2))
- [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, Yarin Gal, Zoubin Ghahramani, Published in ICML 2015](https://www.semanticscholar.org/paper/Dropout-as-a-Bayesian-Approximation%3A-Representing-Gal-Ghahramani/f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6)
- [MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks, Published in IEEE/CVF Conference on Computer Vision and Pattern Recognition 2017, https://doi.org/10.1109/CVPR.2018.00171](https://www.semanticscholar.org/paper/MorphNet%3A-Fast-%26-Simple-Resource-Constrained-of/e60f693cb12132c7fffc34dc141bcc3c9dfd4961) ([MorphNet: Towards Faster and Smaller Neural Networks ](https://ai.googleblog.com/2019/04/morphnet-towards-faster-and-smaller.html))

## Resources
- [Study E-Book (Computer Vision Deep Learning Machine Learning Math NLP Python Reinforcement Learning)](https://github.com/changwookjun/StudyBook)
- [How three machine learning algorithms try to classify handwritten digits as they are being drawn](https://github.com/trevorData/MNIST)
- [Neural Network Based Optimal Control: Resilience to Missed Thrust Events for Long Duration Transfers – ASC- 2019](https://gereshes.com/2019/09/09/neural-network-based-optimal-control-resilience-to-missed-thrust-events-for-long-duration-transfers-asc-2019/)
- [Ari Rubinsztejn Research - Artificial Intelligence in Astrodynamics](https://gereshes.com/)

## Presentations
- [Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions, Jiazheng Yuan](https://andreask.cs.illinois.edu/cs598apk-f18/talks/jyuan18.pdf) ([index of](https://andreask.cs.illinois.edu/cs598apk-f18/talks/))
- [Fast R-CNN, Ross Girshick](http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf)

## Code / Library
- [Convolutional Neural Network (CNN), 5KK73 GPU Assignment 2013](https://sites.google.com/site/5kk73gpu2013/assignment/cnn)
- [OverFeat](https://github.com/sermanet/OverFeat)
- [SRmeetsPS (Depth Super-Resolution Meets Uncalibrated Photometric Stereo)](https://github.com/pengsongyou/SRmeetsPS)
- [JAX: Autograd and XLA](https://github.com/google/jax)
- [Lightnet](https://gitlab.com/EAVISE/lightnet) (Darknet in PyTorch)

## Libraries presentation
- [Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions, Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis, Priya Goyal, Zach DeVito, William S. Moses, Sven Verdoolaege, Andrew Adams, Albert Cohen, Published in ArXiv 2018](https://www.semanticscholar.org/paper/Tensor-Comprehensions%3A-Framework-Agnostic-Machine-Vasilache-Zinenko/cae9d90524cccac5081666985d5d055b71697cee) ([arXiv](https://arxiv.org/abs/1802.04730))
- [From Research to Production With PyTorch 1.0, Peter Goldsborough](https://www.socallinuxexpo.org/sites/default/files/presentations/pytorch.pdf)
- [What is PyTorch?](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9830-training-ai-models-faster-with-distributed-training-in-pytorch-part1.pdf)
- [Accelerating ML Development With PyTorch, Soumith Chintala](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9830-training-ai-models-faster-with-distributed-training-in-pytorch-part2.pdf)
- [PyTorch, JIT, Android, Thomas Viehmann](http://lernapparat.de/static/artikel/pytorch-jit-android/thomas_viehmann.pytorch_jit_android_2018-12-11.pdf)
- [Intel Math Kernel Library for Deep Neural Networks (Intel MKL-DNN)](https://www.alcf.anl.gov/files/Gouicem_ALCF_SDL_2018_MKLDNN_presentation.pdf)
- [Intel Nervana software stack](https://www.microsigma.fr/media/seminaire/Intel-TCAI-Workshop-slides-Nov-2017/Day02-03-Nervana_Software_Stack-Fayard.pdf)
- [Anatomy of High-Performance Deep Learning Convolutions on SIMD Architectures, Evangelos Georganas, Sasikanth Avancha, Kunal Banerjee, Dhiraj D. Kalamkar, Greg Henry, Hans Pabst, Alexander Heinecke, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis (2018)](https://www.semanticscholar.org/paper/Anatomy-of-High-Performance-Deep-Learning-on-SIMD-Georganas-Avancha/96b45f52832aec44326a0b944df411f7b2d67926) ([arXiv](https://arxiv.org/abs/1808.05567))

## Cloud API
- [The Machine Learning API](https://nanonets.com/)

## Misc
- [Patrick Pérez](https://ptrckprz.github.io/)
- [Andrei Bursuc](https://abursuc.github.io/)
- [Are neural networks prone to catastrophic forgetting?](https://ai.stackexchange.com/questions/13289/are-neural-networks-prone-to-catastrophic-forgetting)
- [Continual learning Workshop NeurIPS 2018](https://sites.google.com/view/continual2018)
